# generated by datamodel-codegen:
#   filename:  input_schema.json
#   timestamp: 2024-06-04T11:58:55+00:00

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field


class EmbeddingsProvider(Enum):
    OpenAIEmbeddings = 'OpenAIEmbeddings'
    CohereEmbeddings = 'CohereEmbeddings'


class ChromaIntegration(BaseModel):
    chromaCollectionName: Optional[str] = Field(
        'chroma',
        description='Name of the chroma collection where the data will be stored',
        title='Chroma collection name',
    )
    chromaClientHost: str = Field(
        ..., description='Host argument for Chroma HTTP Client', title='Chroma host'
    )
    chromaClientPort: Optional[int] = Field(
        8000, description='Port argument for Chroma HTTP Client', title='Chroma port'
    )
    chromaClientSsl: Optional[bool] = Field(
        False, description='Enable/Disable SSL', title='Chroma SSL enabled'
    )
    chromaServerAuthCredentials: Optional[str] = Field(
        None,
        description='Chroma server Auth Static API token.',
        title='Chroma server Auth Static API token credentials',
    )
    chromaClientAuthProvider: Optional[str] = Field(
        'chromadb.auth.token_authn.TokenAuthClientProvider',
        description='Chroma client auth provider',
        title='Chroma client auth provider',
    )
    embeddingsProvider: EmbeddingsProvider = Field(
        ...,
        description='Choose the embeddings provider to use for generating embeddings',
        title='Embeddings provider (as defined in the langchain API)',
    )
    embeddingsConfig: Optional[Dict[str, Any]] = Field(
        None,
        description='Specific configuration for the embeddings. For example, for OpenAI, you can the model name as {"model": "text-embedding-ada-002"})',
        title='Embeddings provider configuration',
    )
    embeddingsApiKey: Optional[str] = Field(
        None,
        description='Enter the API key for the selected embeddings provider, if required. For example, for OpenAI, use the OPENAI_API_KEY, and for Cohere, use the COHERE_API_KEY.',
        title='Embeddings API Key (whenever applicable, depends on provider)',
    )
    datasetFields: List = Field(
        ...,
        description='This array specifies the dataset fields to be selected and stored in the vector store. Only the fields listed here will be included in the vector store. For instance, when using the Website Content Crawler, you might choose to include fields such as `text`, `url`, and `metadata.title` in the vector store.',
        title='A list of dataset fields which should be selected from the dataset results',
    )
    metadataDatasetFields: Optional[Dict[str, Any]] = Field(
        None,
        description='A list of dataset fields which should be selected from the dataset and stored as metadata in the vector stores. \n\n For example, when using the Website Content Crawler, you might want to store `url` in metadata. In this case, use `metadataDatasetFields parameter as follows {"page_url": "url"}`',
        title='A list of dataset fields to be selected from the dataset and stored as metadata in the database',
    )
    metadataObject: Optional[Dict[str, Any]] = Field(
        None,
        description='This object allows you to store custom metadata for every item in the vector store. For example, if you want to store the `domain` as metadata, use the `metadataObject` like this: {"domain": "apify.com"}.',
        title='Custom object to be stored as metadata in the vector store database',
    )
    performChunking: Optional[bool] = Field(
        False,
        description='If set to true, the resulting text will be chunked according to the settings below',
        title='Perform chunking',
    )
    chunkSize: Optional[int] = Field(
        1000,
        description='The maximum character length of each text chunk',
        ge=1,
        title='Chunk size',
    )
    chunkOverlap: Optional[int] = Field(
        0,
        description='The character overlap between text chunks that are next to each other',
        ge=0,
        title='Chunk overlap',
    )
    datasetKeysToItemId: Optional[List[str]] = Field(
        ['url'],
        description='This array contains keys that are used to uniquely identify dataset items, which helps to handle content changes across different runs. For instance, in a web content crawling scenario, the `url` field could serve as a unique identifier for each item.',
        title='Keys for dataset item identification',
    )
    enableDeltaUpdates: Optional[bool] = Field(
        True,
        description='When set to true, this setting enables incremental updates for objects in the database by comparing the changes (deltas) between the crawled dataset items and the existing objects, uniquely identified by the `datasetKeysToItemId` field.\n\n The integration will only add new objects and update those that have changed, reducing unnecessary updates. The `datasetFields`, `metadataDatasetFields`, and `metadataObject` fields are used to determine the changes.',
        title='Enable incremental updates for objects based on deltas',
    )
    expiredObjectDeletionPeriod: Optional[float] = Field(
        30,
        description='This setting allows the integration to manage the deletion of objects from the database that have not been crawled for a specified period. It is typically used in subsequent runs after the initial crawl.\n\nWhen the value is greater than 0, the integration checks if objects have been seen within the last X days (determined by the expiration period). If the objects are expired, they are deleted from the database. The specific value for `deletedExpiredObjectsDays` depends on your use case and how frequently you crawl data.\n\nFor example, if you crawl data daily, you can set `deletedExpiredObjectsDays` to 7 days. If you crawl data weekly, you can set `deletedExpiredObjectsDays` to 30 days.',
        ge=0.0,
        title='Delete expired objects from the database after a specified number of days',
    )
    datasetId: Optional[str] = Field(
        None,
        description='Dataset ID (when running standalone without integration)',
        title='Dataset ID',
    )
