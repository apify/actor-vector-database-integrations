# generated by datamodel-codegen:
#   filename:  input_schema.json
#   timestamp: 2024-05-13T11:54:26+00:00

from __future__ import annotations

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field


class PineconeIntegration(BaseModel):
    pinecone_index_name: str = Field(
        ..., description='Pinecone index name.', title='Pinecone index name'
    )
    pinecone_api_key: str = Field(
        ..., description='Pinecone API KEY', title='Pinecone API KEY'
    )
    openai_api_key: str = Field(
        ..., description='OpenAI API KEY', title='OpenAI API KEY'
    )
    fields: List = Field(
        ...,
        description='Select Dataset fields pushed to Pinecone (supports dot notation)',
        title='Fields',
    )
    metadata_fields: Optional[Dict[str, Any]] = Field(
        None,
        description='Select fields pushed to Pinecone as metadata (supports dot notation)',
        title='Metadata fields',
    )
    metadata_values: Optional[Dict[str, Any]] = Field(
        None,
        description='Custom values pushed to Pinecone for every Dataset item as metadata',
        title='Metadata values',
    )
    perform_chunking: Optional[bool] = Field(
        False,
        description='If set to true, the resulting text will be chunked according to the settings below',
        title='Perform chunking',
    )
    chunk_size: Optional[int] = Field(
        1000,
        description='The maximum character length of each text chunk',
        ge=1,
        title='Chunk size',
    )
    chunk_overlap: Optional[int] = Field(
        0,
        description='The character overlap between text chunks that are next to each other',
        ge=0,
        title='Chunk overlap',
    )
    dataset_id: Optional[str] = Field(
        None,
        description='Dataset ID (when running standalone without integration)',
        title='Dataset ID',
    )
